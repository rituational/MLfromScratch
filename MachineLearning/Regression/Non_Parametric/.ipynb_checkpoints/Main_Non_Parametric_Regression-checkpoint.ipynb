{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Non Parametric Regression"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![](./helper/global_vs_local.PNG)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In linear regression, we fit our model to the whole of the data. To capture all the variance in the data, sometimes we would choose a high variance model (shown in left). Even though the points in the middle of the plot may be captured better with a constant line, we are forced to use polynomial as we are looking at the data at a global level. \n",
    "\n",
    "The plot to right fits the data at local level, and rather than having an equation describing the plot, this can be non parametric. \n",
    "\n",
    "But to get to that, we might want to divide our data into pockets, but we dont want to explicitly deal with it. Rather, we just look at the nieghbourhood of the query point and take decision based on the logic given below."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1 Nearest Neightbour \n",
    "\n",
    "<img src=\"helper/K1.PNG\" alt=\"Drawing\" style=\"width: 600px;\"/>\n",
    "\n",
    "<br>\n",
    "<br>\n",
    "<br>\n",
    "\n",
    "For any query point $ x_{q} $ \n",
    "Find point closest in distance \n",
    "\n",
    " \n",
    "$$ X_{NN} = \\underset{i}{\\min}   distance(x_{i}, x_{q} )  $$\n",
    "\n",
    "\n",
    "$$ \\hat y_{q} = y_{NN} $$ (y corresponding to x closest to q) "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1 NN in 2 dimensional data  \n",
    "\n",
    "<br>\n",
    "\n",
    "<img src=\"helper/K2.PNG\" alt=\"Drawing\" style=\"width: 300px;\"/>\n",
    "\n",
    "Voronoi Tesselation : Divide space into N regions each containting single datapoint. Where any predicted example lying in the space, distance is calculated to nearest all data points. The prediction is given as per min distance.\n",
    "\n",
    "For 2D data (and similar plot can be imagined in higher dimensions) we can visualize our plane segmented into N regions based on N data points. \n",
    "We dont actually need to do this division. Rather for every query point, we just calculate the point with minimum distance."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Metrics \n",
    "\n",
    "We are to compute distance between datapoints, we used euclidean distance in the 1D, 2D example above. But we have many other choices. \n",
    "\n",
    "<br>\n",
    "\n",
    "Eg:\n",
    "* Scaled Eucledian Distance\n",
    "    * For our housing price prediction, e may want to give feature importance, so we can weigh our distances for each feature differently \n",
    "    * $$ distance(x_{i},x_{q}) = \\sqrt{a_{1}(x_{j}[1]-x_{q})^2 + a_{j}(x_{j}[i]-x_{q})^2 + a_{d}(x_{j}[d]-x_{q})^2}$$\n",
    "     where d = no. of features \n",
    "* Manhattan Distance\n",
    "    * Imagine you are driving on the streets of New York. So you find distance along x, then y; this is different than euclidean which will just take the diagonal. \n",
    "    * Other choices: Mahanobis, Hamming, cosine simiarity etc \n",
    "    \n",
    "#### Predictive Surfaces change with the metrics chosen \n",
    "As shown below \n",
    "\n",
    "\n",
    "<img src=\"helper/K3.JPG\" alt=\"Drawing\" style=\"width: 400px;\"/>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1 NN Pseudo Code \n",
    "\n",
    "dist1NN = $\\infty$\n",
    "\n",
    "for i = 0, 1,... N: <br>\n",
    "    $ \\delta = distance(x_{i},x_{q}) $ <br>\n",
    "    $\\qquad$ if  $ \\delta  $ < dist1NN:<br>\n",
    "    $\\qquad$$\\qquad$ dist1NN = $\\delta$ <br>\n",
    "    $\\qquad$$\\qquad$ $X_{NN} = x_{i}$\n",
    "   \n",
    "$ Y_{NN} = y_{i} $"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1 NN Disadvantage\n",
    "\n",
    "1 NN **doesnt interpolate well** as shown below \n",
    "\n",
    "<img src=\"helper/K4.PNG\" alt=\"Drawing\" style=\"width: 800px;\"/>\n",
    "\n",
    "\n",
    "**Sensitive to noise** in data. (high variance model)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## K Nearest Neighbours\n",
    "\n",
    "To reduce the effect of noise, we can look at k neighbours rather than only one. (Real estate agents may look for multiple similar houses and give you average house price raher than looking for just one closest house)\n",
    "\n",
    "### K NN Pseudo Code \n",
    "\n",
    "\\# initialize with first k entries in dataset (sorted in ascending distance to query point : $X_{NN_k} $ is farthest)<br><br>\n",
    "$ X_{NN_1}, X_{NN_2},.. X_{NN_k} = x_{1},  x_{2},...  x_{k} $ <br>\n",
    "$ DistNN_1, DistNN_2,.. DistNN_k = sorted list(\\delta(1,j), \\delta(2,j) ...\\delta(k,j)) $  \n",
    "<br>\n",
    "<br>\n",
    "\n",
    "for i = k+1,... N: <br>\n",
    "$\\qquad$ \n",
    "    $ \\delta = distance(x_{i},x_{q}) $ <br>\n",
    "    $\\qquad$$\\qquad$ if $\\delta < DistNN_k: $ <br>\n",
    "    $\\qquad$$\\qquad$$\\qquad$ find j s.t. $ DistNN_j$ "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
