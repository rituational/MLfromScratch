{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "### Metrics\r\n",
    "\r\n",
    "* Throughput: Number of images that can be processed per unit time \r\n",
    "* Speedup: Ratio of sequential vs parallel counterpart\r\n",
    "* Scalability: Handle growing amount of work efficiently. "
   ],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Types of Parallelism\r\n",
    "\r\n",
    "### Data Parallelism\r\n",
    "* Data divided into multiple subsets and same replicated model trained in different GPU\r\n",
    "* At the end of each batch, parameters needs to be shared to all other GPUs\r\n",
    "Scales well with increase in data.\r\n",
    "* Less communication between nodes, but the whole model needs to be fit in one node \r\n",
    "* Good fit for CNN training. \r\n",
    "\r\n",
    "### Model Parallelism\r\n",
    "* * also k. as network parallelism\r\n",
    "* * Model is segmented into different parts nad each part runs same data \r\n",
    "* * depends on degree of parallelism of the network, complex to implement\r\n",
    "* * May decrease communication need as the shared parameters needs to be shared only once for, back step\r\n",
    "![](helper/1.JPG)\r\n",
    "\r\n",
    "\r\n",
    "## Concurrency in data parallelism\r\n",
    "\r\n",
    "### Synchronous vs asynchronous \r\n",
    "\r\n",
    "Types of synchronous: \r\n",
    "\r\n",
    "![](helper/2.JPG)\r\n",
    "![](helper/3.JPG)\r\n"
   ],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "### Usage \r\n",
    "\r\n",
    "mirrored_strategy = tf.distribute.MirroredStrategy(devices=[\"/gpu:0\", \"/gpu:1\"])\r\n",
    "\r\n",
    "with mirrored_strategy.scope():\r\n",
    "     model = ....\r\n",
    "     .....\r\n",
    "\r\n",
    "\r\n",
    "batchsize = max_batch_per_gpu*no._of_gpus\r\n",
    "lr = kr_1_gpu*no_of_gpu"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "Ref: https://towardsdatascience.com/scalable-deep-learning-on-parallel-and-distributed-infrastructures-e5fb4a956bef"
   ],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "Ref for deplth: (didnt understand much tohugh) https://arxiv.org/pdf/1802.09941.pdf"
   ],
   "metadata": {}
  }
 ],
 "metadata": {
  "orig_nbformat": 4,
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}