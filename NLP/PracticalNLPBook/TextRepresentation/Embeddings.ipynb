{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Untitled3.ipynb",
      "provenance": [],
      "authorship_tag": "ABX9TyM1GXE2i7nVKNIYkHFBuqAH",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/rituational/MLfromScratch/blob/master/NLP/PracticalNLPBook/TextRepresentation/Embeddings.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "f0R8riJ7jCjb",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "d47fcc7a-28a2-4b0a-e171-a8ff96a7ebe7"
      },
      "source": [
        "# To install only the requirements of this notebook, uncomment the lines below and run this cell\n",
        "\n",
        "# ===========================\n",
        "\n",
        "!pip install scikit-learn==0.21.3\n",
        "!pip install wget==3.2\n",
        "!pip install gensim==3.6.0\n",
        "!pip install psutil==5.4.8\n",
        "!pip install spacy==2.2.4"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting scikit-learn==0.21.3\n",
            "  Downloading scikit_learn-0.21.3-cp37-cp37m-manylinux1_x86_64.whl (6.7 MB)\n",
            "\u001b[K     |████████████████████████████████| 6.7 MB 5.0 MB/s \n",
            "\u001b[?25hRequirement already satisfied: numpy>=1.11.0 in /usr/local/lib/python3.7/dist-packages (from scikit-learn==0.21.3) (1.19.5)\n",
            "Requirement already satisfied: joblib>=0.11 in /usr/local/lib/python3.7/dist-packages (from scikit-learn==0.21.3) (1.1.0)\n",
            "Requirement already satisfied: scipy>=0.17.0 in /usr/local/lib/python3.7/dist-packages (from scikit-learn==0.21.3) (1.4.1)\n",
            "Installing collected packages: scikit-learn\n",
            "  Attempting uninstall: scikit-learn\n",
            "    Found existing installation: scikit-learn 0.22.2.post1\n",
            "    Uninstalling scikit-learn-0.22.2.post1:\n",
            "      Successfully uninstalled scikit-learn-0.22.2.post1\n",
            "Successfully installed scikit-learn-0.21.3\n",
            "Collecting wget==3.2\n",
            "  Downloading wget-3.2.zip (10 kB)\n",
            "Building wheels for collected packages: wget\n",
            "  Building wheel for wget (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for wget: filename=wget-3.2-py3-none-any.whl size=9672 sha256=b1a3f752bb5b6802818e6d3dff8a629b0770e7a1f1bbdc96423db546223048f6\n",
            "  Stored in directory: /root/.cache/pip/wheels/a1/b6/7c/0e63e34eb06634181c63adacca38b79ff8f35c37e3c13e3c02\n",
            "Successfully built wget\n",
            "Installing collected packages: wget\n",
            "Successfully installed wget-3.2\n",
            "Requirement already satisfied: gensim==3.6.0 in /usr/local/lib/python3.7/dist-packages (3.6.0)\n",
            "Requirement already satisfied: smart-open>=1.2.1 in /usr/local/lib/python3.7/dist-packages (from gensim==3.6.0) (5.2.1)\n",
            "Requirement already satisfied: scipy>=0.18.1 in /usr/local/lib/python3.7/dist-packages (from gensim==3.6.0) (1.4.1)\n",
            "Requirement already satisfied: numpy>=1.11.3 in /usr/local/lib/python3.7/dist-packages (from gensim==3.6.0) (1.19.5)\n",
            "Requirement already satisfied: six>=1.5.0 in /usr/local/lib/python3.7/dist-packages (from gensim==3.6.0) (1.15.0)\n",
            "Requirement already satisfied: psutil==5.4.8 in /usr/local/lib/python3.7/dist-packages (5.4.8)\n",
            "Requirement already satisfied: spacy==2.2.4 in /usr/local/lib/python3.7/dist-packages (2.2.4)\n",
            "Requirement already satisfied: wasabi<1.1.0,>=0.4.0 in /usr/local/lib/python3.7/dist-packages (from spacy==2.2.4) (0.8.2)\n",
            "Requirement already satisfied: requests<3.0.0,>=2.13.0 in /usr/local/lib/python3.7/dist-packages (from spacy==2.2.4) (2.23.0)\n",
            "Requirement already satisfied: srsly<1.1.0,>=1.0.2 in /usr/local/lib/python3.7/dist-packages (from spacy==2.2.4) (1.0.5)\n",
            "Requirement already satisfied: thinc==7.4.0 in /usr/local/lib/python3.7/dist-packages (from spacy==2.2.4) (7.4.0)\n",
            "Requirement already satisfied: numpy>=1.15.0 in /usr/local/lib/python3.7/dist-packages (from spacy==2.2.4) (1.19.5)\n",
            "Requirement already satisfied: plac<1.2.0,>=0.9.6 in /usr/local/lib/python3.7/dist-packages (from spacy==2.2.4) (1.1.3)\n",
            "Requirement already satisfied: cymem<2.1.0,>=2.0.2 in /usr/local/lib/python3.7/dist-packages (from spacy==2.2.4) (2.0.6)\n",
            "Requirement already satisfied: catalogue<1.1.0,>=0.0.7 in /usr/local/lib/python3.7/dist-packages (from spacy==2.2.4) (1.0.0)\n",
            "Requirement already satisfied: preshed<3.1.0,>=3.0.2 in /usr/local/lib/python3.7/dist-packages (from spacy==2.2.4) (3.0.6)\n",
            "Requirement already satisfied: tqdm<5.0.0,>=4.38.0 in /usr/local/lib/python3.7/dist-packages (from spacy==2.2.4) (4.62.3)\n",
            "Requirement already satisfied: setuptools in /usr/local/lib/python3.7/dist-packages (from spacy==2.2.4) (57.4.0)\n",
            "Requirement already satisfied: blis<0.5.0,>=0.4.0 in /usr/local/lib/python3.7/dist-packages (from spacy==2.2.4) (0.4.1)\n",
            "Requirement already satisfied: murmurhash<1.1.0,>=0.28.0 in /usr/local/lib/python3.7/dist-packages (from spacy==2.2.4) (1.0.6)\n",
            "Requirement already satisfied: importlib-metadata>=0.20 in /usr/local/lib/python3.7/dist-packages (from catalogue<1.1.0,>=0.0.7->spacy==2.2.4) (4.8.2)\n",
            "Requirement already satisfied: zipp>=0.5 in /usr/local/lib/python3.7/dist-packages (from importlib-metadata>=0.20->catalogue<1.1.0,>=0.0.7->spacy==2.2.4) (3.6.0)\n",
            "Requirement already satisfied: typing-extensions>=3.6.4 in /usr/local/lib/python3.7/dist-packages (from importlib-metadata>=0.20->catalogue<1.1.0,>=0.0.7->spacy==2.2.4) (3.10.0.2)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.7/dist-packages (from requests<3.0.0,>=2.13.0->spacy==2.2.4) (2021.10.8)\n",
            "Requirement already satisfied: idna<3,>=2.5 in /usr/local/lib/python3.7/dist-packages (from requests<3.0.0,>=2.13.0->spacy==2.2.4) (2.10)\n",
            "Requirement already satisfied: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in /usr/local/lib/python3.7/dist-packages (from requests<3.0.0,>=2.13.0->spacy==2.2.4) (1.24.3)\n",
            "Requirement already satisfied: chardet<4,>=3.0.2 in /usr/local/lib/python3.7/dist-packages (from requests<3.0.0,>=2.13.0->spacy==2.2.4) (3.0.4)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "RLIGMN3Ze8ZG",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "fb24d87c-7e6b-40b0-ef87-89fd310aad74"
      },
      "source": [
        "import os\n",
        "import wget\n",
        "import gzip\n",
        "import shutil\n",
        "\n",
        "gn_vec_path = \"GoogleNews-vectors-negative300.bin\"\n",
        "if not os.path.exists(\"GoogleNews-vectors-negative300.bin\"):\n",
        "    if not os.path.exists(\"../Ch2/GoogleNews-vectors-negative300.bin\"):\n",
        "        #Downloading the reqired model\n",
        "        if not os.path.exists(\"../Ch2/GoogleNews-vectors-negative300.bin.gz\"):\n",
        "            if not os.path.exists(\"GoogleNews-vectors-negative300.bin.gz\"):\n",
        "                wget.download(\"https://s3.amazonaws.com/dl4j-distribution/GoogleNews-vectors-negative300.bin.gz\")\n",
        "            gn_vec_zip_path = \"GoogleNews-vectors-negative300.bin.gz\"\n",
        "        else:\n",
        "            gn_vec_zip_path = \"../Ch2/GoogleNews-vectors-negative300.bin.gz\"\n",
        "        #Extracting the required model\n",
        "        with gzip.open(gn_vec_zip_path, 'rb') as f_in:\n",
        "            with open(gn_vec_path, 'wb') as f_out:\n",
        "                shutil.copyfileobj(f_in, f_out)\n",
        "    else:\n",
        "        gn_vec_path = \"../Ch2/\" + gn_vec_path\n",
        "\n",
        "print(f\"Model at {gn_vec_path}\")"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model at GoogleNews-vectors-negative300.bin\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "3eBB_HKWfsfy"
      },
      "source": [
        "import warnings #This module ignores the various types of warnings generated\n",
        "warnings.filterwarnings(\"ignore\") \n",
        "\n",
        "import psutil #This module helps in retrieving information on running processes and system resource utilization\n",
        "process = psutil.Process(os.getpid())\n",
        "from psutil import virtual_memory\n",
        "mem = virtual_memory()\n",
        "\n",
        "import time #This module is used to calculate the time  "
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "quqQVxyek4-7",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "909adc98-72dc-481b-9967-79728436bd22"
      },
      "source": [
        "from gensim.models import Word2Vec, KeyedVectors\n",
        "pretrainedpath = gn_vec_path\n",
        "\n",
        "#Load W2V model. This will take some time, but it is a one time effort! \n",
        "pre = process.memory_info().rss\n",
        "print(\"Memory used in GB before Loading the Model: %0.2f\"%float(pre/(10**9))) #Check memory usage before loading the model\n",
        "print('-'*10)\n",
        "\n",
        "start_time = time.time() #Start the timer\n",
        "ttl = mem.total #Toal memory available\n",
        "\n",
        "w2v_model = KeyedVectors.load_word2vec_format(pretrainedpath, binary=True) #load the model\n",
        "print(\"%0.2f seconds taken to load\"%float(time.time() - start_time)) #Calculate the total time elapsed since starting the timer\n",
        "print('-'*10)\n",
        "\n",
        "print('Finished loading Word2Vec')\n",
        "print('-'*10)\n",
        "\n",
        "post = process.memory_info().rss\n",
        "print(\"Memory used in GB after Loading the Model: {:.2f}\".format(float(post/(10**9)))) #Calculate the memory used after loading the model\n",
        "print('-'*10)\n",
        "\n",
        "print(\"Percentage increase in memory usage: {:.2f}% \".format(float((post/pre)*100))) #Percentage increase in memory after loading the model\n",
        "print('-'*10)\n",
        "\n",
        "print(\"Numver of words in vocablulary: \",len(w2v_model.vocab)) #Number of words in the vocabulary. "
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Memory used in GB before Loading the Model: 0.17\n",
            "----------\n",
            "55.16 seconds taken to load\n",
            "----------\n",
            "Finished loading Word2Vec\n",
            "----------\n",
            "Memory used in GB after Loading the Model: 5.11\n",
            "----------\n",
            "Percentage increase in memory usage: 2978.50% \n",
            "----------\n",
            "Numver of words in vocablulary:  3000000\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "vFeqTSjak_-Y",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "fd3507a1-ea16-47dd-a45a-45b8e00c219c"
      },
      "source": [
        "#Let us examine the model by knowing what the most similar words are, for a given word!\n",
        "w2v_model.most_similar('beautiful')"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[('gorgeous', 0.8353004455566406),\n",
              " ('lovely', 0.810693621635437),\n",
              " ('stunningly_beautiful', 0.7329413890838623),\n",
              " ('breathtakingly_beautiful', 0.7231341004371643),\n",
              " ('wonderful', 0.6854087114334106),\n",
              " ('fabulous', 0.6700063943862915),\n",
              " ('loveliest', 0.6612576246261597),\n",
              " ('prettiest', 0.6595001816749573),\n",
              " ('beatiful', 0.6593326330184937),\n",
              " ('magnificent', 0.6591402292251587)]"
            ]
          },
          "metadata": {},
          "execution_count": 7
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "rK0b2lVb0UBy",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "ab0408a1-dc58-4c5c-8acd-b71206c15d8c"
      },
      "source": [
        "#Let us try with another word! \n",
        "w2v_model.most_similar('toronto')"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[('montreal', 0.698411226272583),\n",
              " ('vancouver', 0.6587257385253906),\n",
              " ('nyc', 0.6248831748962402),\n",
              " ('alberta', 0.6179691553115845),\n",
              " ('boston', 0.611499547958374),\n",
              " ('calgary', 0.61032634973526),\n",
              " ('edmonton', 0.6100261211395264),\n",
              " ('canadian', 0.5944076776504517),\n",
              " ('chicago', 0.5911980271339417),\n",
              " ('springfield', 0.5888351202011108)]"
            ]
          },
          "metadata": {},
          "execution_count": 8
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "62jfR4iu0adh",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "bc6492d5-8f3e-4dfc-94b4-b80627cb7951"
      },
      "source": [
        "#What is the vector representation for a word? \n",
        "len(w2v_model['computer'])"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "300"
            ]
          },
          "metadata": {},
          "execution_count": 11
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "RKOdsb1u0dZL",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 329
        },
        "outputId": "567cdf68-3a7d-4e49-fe1e-2c20ae7067f7"
      },
      "source": [
        "#What if I am looking for a word that is not in this vocabulary?\n",
        "w2v_model['practicalnlp']"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "error",
          "ename": "KeyError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-12-354849ef77a2>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;31m#What if I am looking for a word that is not in this vocabulary?\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m \u001b[0mw2v_model\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'practicalnlp'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/gensim/models/keyedvectors.py\u001b[0m in \u001b[0;36m__getitem__\u001b[0;34m(self, entities)\u001b[0m\n\u001b[1;32m    335\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0misinstance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mentities\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mstring_types\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    336\u001b[0m             \u001b[0;31m# allow calls like trained_model['office'], as a shorthand for trained_model[['office']]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 337\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_vector\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mentities\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    338\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    339\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mvstack\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_vector\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mentity\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mentity\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mentities\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/gensim/models/keyedvectors.py\u001b[0m in \u001b[0;36mget_vector\u001b[0;34m(self, word)\u001b[0m\n\u001b[1;32m    453\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    454\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mget_vector\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mword\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 455\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mword_vec\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mword\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    456\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    457\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mwords_closer_than\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mw1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mw2\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/gensim/models/keyedvectors.py\u001b[0m in \u001b[0;36mword_vec\u001b[0;34m(self, word, use_norm)\u001b[0m\n\u001b[1;32m    450\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0mresult\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    451\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 452\u001b[0;31m             \u001b[0;32mraise\u001b[0m \u001b[0mKeyError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"word '%s' not in vocabulary\"\u001b[0m \u001b[0;34m%\u001b[0m \u001b[0mword\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    453\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    454\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mget_vector\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mword\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mKeyError\u001b[0m: \"word 'practicalnlp' not in vocabulary\""
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "G3MCLUK00v7v"
      },
      "source": [
        "* Tokens are lowercased \n",
        "* If token not present, it throws an error \n",
        "For a sentence, we can sum/average the embeddings for the constituent words. "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "HPuZ9kvP0mjD",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "679f982d-18dd-45f4-beee-2b9b1b344da6"
      },
      "source": [
        "# Using SpaCy\n",
        "\n",
        "!python -m spacy download en_core_web_md\n",
        "\n",
        "## Note: Needs a restart of the colab for the code below to work. "
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting en_core_web_md==2.2.5\n",
            "  Downloading https://github.com/explosion/spacy-models/releases/download/en_core_web_md-2.2.5/en_core_web_md-2.2.5.tar.gz (96.4 MB)\n",
            "\u001b[K     |████████████████████████████████| 96.4 MB 1.2 MB/s \n",
            "\u001b[?25hRequirement already satisfied: spacy>=2.2.2 in /usr/local/lib/python3.7/dist-packages (from en_core_web_md==2.2.5) (2.2.4)\n",
            "Requirement already satisfied: preshed<3.1.0,>=3.0.2 in /usr/local/lib/python3.7/dist-packages (from spacy>=2.2.2->en_core_web_md==2.2.5) (3.0.6)\n",
            "Requirement already satisfied: murmurhash<1.1.0,>=0.28.0 in /usr/local/lib/python3.7/dist-packages (from spacy>=2.2.2->en_core_web_md==2.2.5) (1.0.6)\n",
            "Requirement already satisfied: srsly<1.1.0,>=1.0.2 in /usr/local/lib/python3.7/dist-packages (from spacy>=2.2.2->en_core_web_md==2.2.5) (1.0.5)\n",
            "Requirement already satisfied: catalogue<1.1.0,>=0.0.7 in /usr/local/lib/python3.7/dist-packages (from spacy>=2.2.2->en_core_web_md==2.2.5) (1.0.0)\n",
            "Requirement already satisfied: setuptools in /usr/local/lib/python3.7/dist-packages (from spacy>=2.2.2->en_core_web_md==2.2.5) (57.4.0)\n",
            "Requirement already satisfied: numpy>=1.15.0 in /usr/local/lib/python3.7/dist-packages (from spacy>=2.2.2->en_core_web_md==2.2.5) (1.19.5)\n",
            "Requirement already satisfied: plac<1.2.0,>=0.9.6 in /usr/local/lib/python3.7/dist-packages (from spacy>=2.2.2->en_core_web_md==2.2.5) (1.1.3)\n",
            "Requirement already satisfied: thinc==7.4.0 in /usr/local/lib/python3.7/dist-packages (from spacy>=2.2.2->en_core_web_md==2.2.5) (7.4.0)\n",
            "Requirement already satisfied: blis<0.5.0,>=0.4.0 in /usr/local/lib/python3.7/dist-packages (from spacy>=2.2.2->en_core_web_md==2.2.5) (0.4.1)\n",
            "Requirement already satisfied: wasabi<1.1.0,>=0.4.0 in /usr/local/lib/python3.7/dist-packages (from spacy>=2.2.2->en_core_web_md==2.2.5) (0.8.2)\n",
            "Requirement already satisfied: tqdm<5.0.0,>=4.38.0 in /usr/local/lib/python3.7/dist-packages (from spacy>=2.2.2->en_core_web_md==2.2.5) (4.62.3)\n",
            "Requirement already satisfied: requests<3.0.0,>=2.13.0 in /usr/local/lib/python3.7/dist-packages (from spacy>=2.2.2->en_core_web_md==2.2.5) (2.23.0)\n",
            "Requirement already satisfied: cymem<2.1.0,>=2.0.2 in /usr/local/lib/python3.7/dist-packages (from spacy>=2.2.2->en_core_web_md==2.2.5) (2.0.6)\n",
            "Requirement already satisfied: importlib-metadata>=0.20 in /usr/local/lib/python3.7/dist-packages (from catalogue<1.1.0,>=0.0.7->spacy>=2.2.2->en_core_web_md==2.2.5) (4.8.2)\n",
            "Requirement already satisfied: zipp>=0.5 in /usr/local/lib/python3.7/dist-packages (from importlib-metadata>=0.20->catalogue<1.1.0,>=0.0.7->spacy>=2.2.2->en_core_web_md==2.2.5) (3.6.0)\n",
            "Requirement already satisfied: typing-extensions>=3.6.4 in /usr/local/lib/python3.7/dist-packages (from importlib-metadata>=0.20->catalogue<1.1.0,>=0.0.7->spacy>=2.2.2->en_core_web_md==2.2.5) (3.10.0.2)\n",
            "Requirement already satisfied: idna<3,>=2.5 in /usr/local/lib/python3.7/dist-packages (from requests<3.0.0,>=2.13.0->spacy>=2.2.2->en_core_web_md==2.2.5) (2.10)\n",
            "Requirement already satisfied: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in /usr/local/lib/python3.7/dist-packages (from requests<3.0.0,>=2.13.0->spacy>=2.2.2->en_core_web_md==2.2.5) (1.24.3)\n",
            "Requirement already satisfied: chardet<4,>=3.0.2 in /usr/local/lib/python3.7/dist-packages (from requests<3.0.0,>=2.13.0->spacy>=2.2.2->en_core_web_md==2.2.5) (3.0.4)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.7/dist-packages (from requests<3.0.0,>=2.13.0->spacy>=2.2.2->en_core_web_md==2.2.5) (2021.10.8)\n",
            "\u001b[38;5;2m✔ Download and installation successful\u001b[0m\n",
            "You can now load the model via spacy.load('en_core_web_md')\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "QScRaBEX1Hvb",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "016d27a8-b8f7-405f-973f-4f5eb876c77b"
      },
      "source": [
        "import spacy\n",
        "\n",
        "%time \n",
        "nlp = spacy.load('en_core_web_md')\n",
        "# process a sentence using the model\n",
        "mydoc = nlp(\"Canada is a large country\")\n",
        "#Get a vector for individual words\n",
        "#print(doc[0].vector) #vector for 'Canada', the first word in the text \n",
        "print(mydoc.vector) #Averaged vector for the entire sentence"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "CPU times: user 1 µs, sys: 1e+03 ns, total: 2 µs\n",
            "Wall time: 5.01 µs\n",
            "[-1.12055197e-01  2.26087615e-01 -5.15111461e-02 -1.21812008e-01\n",
            "  4.13958639e-01 -8.56475979e-02 -2.84600933e-03 -2.26096585e-01\n",
            "  6.98113963e-02  2.27946019e+00 -4.49774921e-01 -6.39050007e-02\n",
            " -1.80326015e-01 -8.79765972e-02  9.93399299e-04 -1.57384202e-01\n",
            " -1.23817801e-01  1.54990411e+00  2.00794004e-02  1.38399601e-01\n",
            " -1.48897991e-01 -2.23025799e-01 -1.48171991e-01  4.68924567e-02\n",
            " -3.17026004e-02  1.19096041e-02 -6.10985979e-02  9.57068056e-02\n",
            "  9.37099904e-02  1.70955807e-01 -9.29740071e-03  7.88536817e-02\n",
            "  1.74508005e-01 -1.04450598e-01  1.04872189e-01 -1.16961405e-01\n",
            "  6.23028055e-02 -2.23016590e-01 -1.44107476e-01 -2.03423887e-01\n",
            "  2.61404991e-01  2.43404001e-01  1.51980996e-01 -1.12484001e-01\n",
            "  1.18055798e-01 -9.51323956e-02  8.66319984e-02 -2.54322797e-01\n",
            "  3.84932049e-02  1.18278004e-01 -3.21602583e-01  3.73764008e-01\n",
            "  1.13018408e-01 -8.05834010e-02  1.84921592e-01  9.38879885e-03\n",
            "  1.22166201e-01 -3.24288011e-02  1.01590000e-01 -1.56877995e-01\n",
            " -2.57006437e-02  1.63392588e-01  1.06118001e-01  2.25193188e-01\n",
            "  8.06204006e-02 -1.21081993e-01 -1.52107209e-01  8.25726017e-02\n",
            " -6.09899946e-02  1.44145802e-01  2.01554038e-02  2.54258011e-02\n",
            "  1.06071997e-02  6.37948066e-02  1.10551611e-01 -6.40176088e-02\n",
            " -6.36451989e-02 -9.99798030e-02 -7.01020136e-02  3.09334368e-01\n",
            "  5.68300001e-02  3.63879651e-03 -1.65255398e-01  2.98442870e-01\n",
            "  4.01660334e-03 -1.73631594e-01  5.15965708e-02  1.61811799e-01\n",
            "  2.20304996e-01 -8.29614028e-02 -2.64678001e-01  2.44114012e-01\n",
            "  3.48895532e-03 -1.57521993e-01  1.67974800e-01  1.05541132e-01\n",
            " -1.31224409e-01  7.17941970e-02  1.39708191e-01 -1.95359858e-03\n",
            " -8.55428055e-02  1.20119795e-01 -6.84404075e-02  5.14601183e-04\n",
            " -2.86250003e-02 -1.10662603e+00  2.02491835e-01 -1.50410801e-01\n",
            "  6.51507173e-03 -3.30360234e-03  1.21523812e-01 -1.61614027e-02\n",
            " -1.43233404e-01 -9.88139957e-02 -2.17486005e-02  1.81988999e-01\n",
            "  8.85506049e-02  2.72242010e-01 -7.73219988e-02  1.43622067e-02\n",
            " -1.57062009e-01  4.01146002e-02  3.90305184e-02 -1.42812401e-01\n",
            " -2.08329991e-01  9.64459926e-02  1.42821997e-01 -1.94155991e-01\n",
            "  5.37982993e-02 -1.00471973e-02  1.94714032e-02 -9.83514041e-02\n",
            " -4.17162031e-02  1.23069003e-01  1.68428212e-01 -1.17991492e-01\n",
            " -2.56704390e-01 -1.89464003e-01  9.22677964e-02 -1.72503412e-01\n",
            " -1.11929202e+00  6.42500073e-03  3.51435989e-01  8.19059983e-02\n",
            "  4.92408946e-02 -1.80243999e-01  1.82863399e-01  8.92240033e-02\n",
            "  2.47399211e-01  2.74492018e-02 -2.49322020e-02  2.35055804e-01\n",
            "  8.12319964e-02 -1.86482631e-02 -1.06439434e-01  5.28851971e-02\n",
            " -1.02569997e-01  1.35777995e-01 -2.32603997e-01  9.24602076e-02\n",
            "  1.92440599e-01  1.48551196e-01  5.57186007e-02  3.97088043e-02\n",
            " -6.74048066e-03  9.73687991e-02  2.62231939e-02 -8.26509967e-02\n",
            "  1.30085424e-01 -1.38572007e-01 -4.11808006e-02 -4.13070023e-02\n",
            " -3.41880023e-02  1.28202796e-01 -6.66912049e-02 -7.41944537e-02\n",
            " -5.87003939e-02  1.36300415e-01  1.67494014e-01  1.71119809e-01\n",
            "  1.18692197e-01  2.30142009e-02 -2.06086040e-02 -3.85930002e-01\n",
            " -1.17673976e-02 -7.34595209e-02 -3.43096368e-02 -7.80718103e-02\n",
            " -2.81003956e-02 -7.30765983e-02 -2.21649408e-01 -1.02057599e-01\n",
            "  5.11020012e-02 -9.07440037e-02 -4.69896048e-02 -2.10200553e-03\n",
            "  1.05816983e-01  4.79107983e-02  1.03080198e-01 -8.96641985e-02\n",
            "  8.85651931e-02 -9.09178331e-02 -5.16167991e-02  1.50742605e-01\n",
            "  3.07500213e-01 -4.05239780e-03  1.04269005e-01  3.55780013e-02\n",
            "  1.16165996e-01 -2.97939777e-03 -1.42966792e-01  5.00957891e-02\n",
            " -1.08308598e-01  1.68199837e-03  1.36314392e-01  1.48694202e-01\n",
            " -3.17817986e-01  1.21000603e-01 -1.59556001e-01  7.51644000e-02\n",
            " -1.03386201e-01  1.10754207e-01  8.20529982e-02 -6.02059904e-03\n",
            "  1.35578603e-01 -4.08943966e-02  6.05328009e-02  1.03734590e-01\n",
            " -6.22724071e-02  2.30276197e-01  1.30762011e-01  1.51950002e-01\n",
            "  7.40183964e-02 -1.84507206e-01 -1.33174613e-01 -1.49338007e-01\n",
            "  1.19309977e-01 -2.41554022e-01 -1.00904807e-01  1.54562384e-01\n",
            " -7.63845369e-02  1.66379198e-01  2.20374197e-01  1.58361979e-02\n",
            "  1.80677801e-01 -1.77342609e-01  2.22857997e-01 -2.99477577e-01\n",
            " -1.53620601e-01 -2.67919600e-01  1.56353399e-01 -1.74718007e-01\n",
            "  1.83644608e-01  1.28259212e-01 -6.30084053e-02  2.68236816e-01\n",
            "  2.10368007e-01 -4.73994762e-02 -1.09680817e-01  1.62620202e-01\n",
            "  8.96113962e-02  1.50361210e-01 -1.55037967e-02  1.50141995e-02\n",
            "  1.76618043e-02 -2.28057191e-01  7.85290003e-02 -4.59632799e-02\n",
            "  1.98103897e-02 -1.71379801e-02 -1.45676598e-01 -3.32076550e-02\n",
            " -2.09102005e-01 -2.48584002e-01 -8.51256028e-02  4.25900035e-02\n",
            " -1.33966401e-01  2.89979968e-02  2.10713193e-01 -1.86206046e-02\n",
            "  1.71603993e-01  2.21868396e-01 -2.10479975e-01  1.49794608e-01\n",
            " -1.10692397e-01 -4.47340589e-03  5.13652042e-02 -7.27116019e-02\n",
            "  6.07413948e-02 -8.13369974e-02 -1.94639400e-01 -5.06809242e-02\n",
            "  6.40980080e-02 -2.20814198e-01  2.96969917e-02  1.53438210e-01\n",
            " -2.18270030e-02 -1.93358198e-01 -2.26220220e-01  1.84093148e-01]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "B5RWss651g6n",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "0aff0441-645d-400d-f269-15fa10847342"
      },
      "source": [
        "#What happens when I give a sentence with strange words (and stop words), and try to get its word vector in Spacy?\n",
        "temp = nlp('practicalnlp is a newword')\n",
        "temp[0].vector\n",
        "# So it doesnt throw an error. "
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
              "       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
              "       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
              "       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
              "       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
              "       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
              "       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
              "       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
              "       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
              "       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
              "       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
              "       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
              "       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
              "       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
              "       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
              "       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
              "       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
              "       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.], dtype=float32)"
            ]
          },
          "metadata": {},
          "execution_count": 2
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "9V6D0szR2yoO"
      },
      "source": [
        "### Training Word Embeddings\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "FEh5NuvF2aJo",
        "outputId": "22b01de9-2637-48f8-de03-9cc3ff72d6f8",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "# To install only the requirements of this notebook, uncomment the lines below and run this cell\n",
        "\n",
        "# ===========================\n",
        "\n",
        "!pip install gensim==3.6.0\n",
        "!pip install requests==2.23.0\n",
        "\n",
        "# ==========================="
      ],
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: gensim==3.6.0 in /usr/local/lib/python3.7/dist-packages (3.6.0)\n",
            "Requirement already satisfied: numpy>=1.11.3 in /usr/local/lib/python3.7/dist-packages (from gensim==3.6.0) (1.19.5)\n",
            "Requirement already satisfied: six>=1.5.0 in /usr/local/lib/python3.7/dist-packages (from gensim==3.6.0) (1.15.0)\n",
            "Requirement already satisfied: scipy>=0.18.1 in /usr/local/lib/python3.7/dist-packages (from gensim==3.6.0) (1.4.1)\n",
            "Requirement already satisfied: smart-open>=1.2.1 in /usr/local/lib/python3.7/dist-packages (from gensim==3.6.0) (5.2.1)\n",
            "Requirement already satisfied: requests==2.23.0 in /usr/local/lib/python3.7/dist-packages (2.23.0)\n",
            "Requirement already satisfied: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in /usr/local/lib/python3.7/dist-packages (from requests==2.23.0) (1.24.3)\n",
            "Requirement already satisfied: chardet<4,>=3.0.2 in /usr/local/lib/python3.7/dist-packages (from requests==2.23.0) (3.0.4)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.7/dist-packages (from requests==2.23.0) (2021.10.8)\n",
            "Requirement already satisfied: idna<3,>=2.5 in /usr/local/lib/python3.7/dist-packages (from requests==2.23.0) (2.10)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "9AqQS7sh3Faj"
      },
      "source": [
        "from gensim.models import Word2Vec\n",
        "import warnings\n",
        "warnings.filterwarnings('ignore')"
      ],
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "6NtTGe0j30BO"
      },
      "source": [
        "# define training data\n",
        "#Genism word2vec requires that a format of ‘list of lists’ be provided for training where every document contained in a list.\n",
        "#Every list contains lists of tokens of that document.\n",
        "corpus = [['dog','bites','man'], [\"man\", \"bites\" ,\"dog\"],[\"dog\",\"eats\",\"meat\"],[\"man\", \"eats\",\"food\"]]\n",
        "\n",
        "#Training the model\n",
        "model_cbow = Word2Vec(corpus, min_count=1,sg=0) #using CBOW Architecture for trainnig\n",
        "model_skipgram = Word2Vec(corpus, min_count=1,sg=1)#using skipGram Architecture for training "
      ],
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "7P6mWi8Z4DVr",
        "outputId": "3ae42a13-b1d4-448f-9de9-f35e27747f64",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "#Summarize the loaded model\n",
        "print(model_cbow)\n",
        "\n",
        "#Summarize vocabulary\n",
        "words = list(model_cbow.wv.vocab)\n",
        "print(words)\n",
        "\n",
        "#Acess vector for one word\n",
        "print(model_cbow['dog'])"
      ],
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Word2Vec(vocab=6, size=100, alpha=0.025)\n",
            "['dog', 'bites', 'man', 'eats', 'meat', 'food']\n",
            "[-0.00194398  0.00393738  0.00369967 -0.00235479  0.00364519 -0.00453437\n",
            "  0.00209946 -0.00166912  0.00422106  0.00431825  0.00275713 -0.0036539\n",
            "  0.00024157 -0.00362418  0.00328706 -0.00376305  0.00061169 -0.00377349\n",
            "  0.0007469  -0.00080296 -0.00250923 -0.00043262  0.00171664 -0.00480816\n",
            "  0.00177381 -0.00029488 -0.00453655  0.0033243  -0.0045674   0.0039944\n",
            " -0.00221599 -0.00458711  0.00365662 -0.00076582  0.0016429  -0.00264037\n",
            " -0.00240134 -0.00401012  0.00164633  0.00402984 -0.00441488 -0.00363363\n",
            "  0.00318341 -0.00269756 -0.00014105 -0.00439145 -0.00195309 -0.00027609\n",
            "  0.00471698  0.0002547  -0.0042338   0.00147057  0.00091033  0.00040762\n",
            " -0.0036352   0.00421523 -0.00205616 -0.00458467 -0.00482435  0.00061726\n",
            "  0.00181969  0.00247203  0.00355255 -0.00462221  0.00429353  0.00273921\n",
            " -0.00445183 -0.00149844 -0.00060953 -0.0040787  -0.00293841 -0.00199496\n",
            " -0.003579   -0.00222388 -0.00157758 -0.00434557  0.00202644 -0.00161615\n",
            " -0.00061686  0.00289975 -0.00385648  0.00256523 -0.0026743   0.00129347\n",
            " -0.00071139 -0.0001807  -0.00297632  0.00155017  0.00190533  0.00024721\n",
            "  0.00088394  0.00150945 -0.00441741 -0.0007514  -0.00308642  0.00126616\n",
            "  0.00279213 -0.0048939   0.00340581  0.00069507]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "iAZpuyU24Go0",
        "outputId": "1cd59189-6947-4fd7-e398-439b447b2365",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "#Compute similarity \n",
        "print(\"Similarity between eats and bites:\",model_cbow.similarity('eats', 'bites'))\n",
        "print(\"Similarity between eats and man:\",model_cbow.similarity('eats', 'man'))"
      ],
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Similarity between eats and bites: 0.14955705\n",
            "Similarity between eats and man: -0.06328051\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "xOr5YVHt4LCN",
        "outputId": "cb124771-24fe-4279-f300-a60ab91af3b4",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "#Most similarity\n",
        "model_cbow.most_similar('meat')"
      ],
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[('dog', 0.00042568519711494446),\n",
              " ('bites', -0.02458595484495163),\n",
              " ('food', -0.05290638282895088),\n",
              " ('man', -0.0554637536406517),\n",
              " ('eats', -0.09762006253004074)]"
            ]
          },
          "metadata": {},
          "execution_count": 9
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "BUAuaUEp4V6X",
        "outputId": "b427a7a4-cf24-42b1-de10-28e6a0aa2968",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "# save model\n",
        "model_cbow.save('model_cbow.bin')\n",
        "\n",
        "# load model\n",
        "new_model_cbow = Word2Vec.load('model_cbow.bin')\n",
        "print(new_model_cbow)"
      ],
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Word2Vec(vocab=6, size=100, alpha=0.025)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "vvwbhPvN4Zig",
        "outputId": "0a1b4609-adbf-4d64-9019-2a167e984642",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "#Summarize the loaded model\n",
        "print(model_skipgram)\n",
        "\n",
        "#Summarize vocabulary\n",
        "words = list(model_skipgram.wv.vocab)\n",
        "print(words)\n",
        "\n",
        "#Acess vector for one word\n",
        "print(model_skipgram['dog'])"
      ],
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Word2Vec(vocab=6, size=100, alpha=0.025)\n",
            "['dog', 'bites', 'man', 'eats', 'meat', 'food']\n",
            "[-0.00194398  0.00393738  0.00369967 -0.00235479  0.00364519 -0.00453437\n",
            "  0.00209946 -0.00166912  0.00422106  0.00431825  0.00275713 -0.0036539\n",
            "  0.00024157 -0.00362418  0.00328706 -0.00376305  0.00061169 -0.00377349\n",
            "  0.0007469  -0.00080296 -0.00250923 -0.00043262  0.00171664 -0.00480816\n",
            "  0.00177381 -0.00029488 -0.00453655  0.0033243  -0.0045674   0.0039944\n",
            " -0.00221599 -0.00458711  0.00365662 -0.00076582  0.0016429  -0.00264037\n",
            " -0.00240134 -0.00401012  0.00164633  0.00402984 -0.00441488 -0.00363363\n",
            "  0.00318341 -0.00269756 -0.00014105 -0.00439145 -0.00195309 -0.00027609\n",
            "  0.00471698  0.0002547  -0.0042338   0.00147057  0.00091033  0.00040762\n",
            " -0.0036352   0.00421523 -0.00205616 -0.00458467 -0.00482435  0.00061726\n",
            "  0.00181969  0.00247203  0.00355255 -0.00462221  0.00429353  0.00273921\n",
            " -0.00445183 -0.00149844 -0.00060953 -0.0040787  -0.00293841 -0.00199496\n",
            " -0.003579   -0.00222388 -0.00157758 -0.00434557  0.00202644 -0.00161615\n",
            " -0.00061686  0.00289975 -0.00385648  0.00256523 -0.0026743   0.00129347\n",
            " -0.00071139 -0.0001807  -0.00297632  0.00155017  0.00190533  0.00024721\n",
            "  0.00088394  0.00150945 -0.00441741 -0.0007514  -0.00308642  0.00126616\n",
            "  0.00279213 -0.0048939   0.00340581  0.00069507]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "mMhWD1Yf4-NR",
        "outputId": "4b351f23-d4ba-4739-ff4b-ef59b2700932",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "#Compute similarity \n",
        "print(\"Similarity between eats and bites:\",model_skipgram.similarity('eats', 'bites'))\n",
        "print(\"Similarity between eats and man:\",model_skipgram.similarity('eats', 'man'))"
      ],
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Similarity between eats and bites: 0.14955786\n",
            "Similarity between eats and man: -0.06327551\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "8Wn_ZXkb5FXk",
        "outputId": "ff6dc68c-615e-44e6-8486-3249508d99c4",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "#Most similarity\n",
        "model_skipgram.most_similar('meat')\n"
      ],
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[('dog', 0.0004256926476955414),\n",
              " ('bites', -0.02458595484495163),\n",
              " ('food', -0.05290639400482178),\n",
              " ('man', -0.0554637610912323),\n",
              " ('eats', -0.09770055115222931)]"
            ]
          },
          "metadata": {},
          "execution_count": 13
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "VTKWk02o5KXs",
        "outputId": "2a7ff71d-7ef4-4566-9144-c5c08ccfebf4",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "# save model\n",
        "model_skipgram.save('model_skipgram.bin')\n",
        "\n",
        "# load model\n",
        "new_model_skipgram = Word2Vec.load('model_skipgram.bin')\n",
        "print(new_model_skipgram)"
      ],
      "execution_count": 14,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Word2Vec(vocab=6, size=100, alpha=0.025)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ZFwGH8yP5OgX"
      },
      "source": [
        "#### Training Embedding on Wiki Corpus \n",
        "\n",
        "Hyperparameter:\n",
        "* which algorithm to use (sg)\n",
        "* The min frequency of a word to qualify for training  (min_count)"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "AvjBXC-b5NQX",
        "outputId": "a54a5790-517d-4aac-bada-d447b52f6840",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "import os\n",
        "import requests\n",
        "\n",
        "os.makedirs('data/en', exist_ok= True)\n",
        "file_name = \"data/en/enwiki-latest-pages-articles-multistream14.xml-p13159683p14324602.bz2\"\n",
        "file_id = \"11804g0GcWnBIVDahjo5fQyc05nQLXGwF\"\n",
        "\n",
        "def download_file_from_google_drive(id, destination):\n",
        "    URL = \"https://docs.google.com/uc?export=download\"\n",
        "\n",
        "    session = requests.Session()\n",
        "\n",
        "    response = session.get(URL, params = { 'id' : id }, stream = True)\n",
        "    token = get_confirm_token(response)\n",
        "\n",
        "    if token:\n",
        "        params = { 'id' : id, 'confirm' : token }\n",
        "        response = session.get(URL, params = params, stream = True)\n",
        "\n",
        "    save_response_content(response, destination)    \n",
        "\n",
        "def get_confirm_token(response):\n",
        "    for key, value in response.cookies.items():\n",
        "        if key.startswith('download_warning'):\n",
        "            return value\n",
        "\n",
        "    return None\n",
        "\n",
        "def save_response_content(response, destination):\n",
        "    CHUNK_SIZE = 32768\n",
        "\n",
        "    with open(destination, \"wb\") as f:\n",
        "        for chunk in response.iter_content(CHUNK_SIZE):\n",
        "            if chunk: # filter out keep-alive new chunks\n",
        "                f.write(chunk)\n",
        "\n",
        "if not os.path.exists(file_name):\n",
        "    download_file_from_google_drive(file_id, file_name)\n",
        "else:\n",
        "    print(\"file already exists, skipping download\")\n",
        "\n",
        "print(f\"File at: {file_name}\")"
      ],
      "execution_count": 15,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "File at: data/en/enwiki-latest-pages-articles-multistream14.xml-p13159683p14324602.bz2\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "gRM4VQpW5hXU"
      },
      "source": [
        "from gensim.corpora.wikicorpus import WikiCorpus\n",
        "from gensim.models.word2vec import Word2Vec\n",
        "from gensim.models.fasttext import FastText\n",
        "import time"
      ],
      "execution_count": 16,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "noqIyiUq5rO1"
      },
      "source": [
        "#Preparing the Training data\n",
        "wiki = WikiCorpus(file_name, lemmatize=False, dictionary={})\n",
        "sentences = list(wiki.get_texts())"
      ],
      "execution_count": 17,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "pWNkck-q5tTB",
        "outputId": "0f4c4fe9-067f-4acb-9f45-ca74033e5301",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "#CBOW\n",
        "start = time.time()\n",
        "word2vec_cbow = Word2Vec(sentences,min_count=10, sg=0)\n",
        "end = time.time()\n",
        "\n",
        "print(\"CBOW Model Training Complete.\\nTime taken for training is:{:.2f} hrs \".format((end-start)/3600.0))"
      ],
      "execution_count": 18,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "CBOW Model Training Complete.\n",
            "Time taken for training is:0.10 hrs \n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "LKiz4O0D6ZPV",
        "outputId": "f972b8bb-f66b-44ce-c657-52419ba9a41e",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "#Summarize the loaded model\n",
        "print(word2vec_cbow)\n",
        "print(\"-\"*30)\n",
        "\n",
        "#Summarize vocabulary\n",
        "words = list(word2vec_cbow.wv.vocab)\n",
        "print(f\"Length of vocabulary: {len(words)}\")\n",
        "print(\"Printing the first 30 words.\")\n",
        "print(words[:30])\n",
        "print(\"-\"*30)\n",
        "\n",
        "#Acess vector for one word\n",
        "print(f\"Length of vector: {len(word2vec_cbow['film'])}\")\n",
        "print(word2vec_cbow['film'])\n",
        "print(\"-\"*30)\n",
        "\n",
        "#Compute similarity \n",
        "print(\"Similarity between film and drama:\",word2vec_cbow.similarity('film', 'drama'))\n",
        "print(\"Similarity between film and tiger:\",word2vec_cbow.similarity('film', 'tiger'))\n",
        "print(\"-\"*30)"
      ],
      "execution_count": 19,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Word2Vec(vocab=111150, size=100, alpha=0.025)\n",
            "------------------------------\n",
            "Length of vocabulary: 111150\n",
            "Printing the first 30 words.\n",
            "['the', 'roses', 'registered', 'as', 'is', 'brisbane', 'racing', 'club', 'group', 'thoroughbred', 'horse', 'race', 'for', 'three', 'year', 'old', 'filles', 'run', 'under', 'set', 'weights', 'conditions', 'over', 'distance', 'of', 'metres', 'at', 'racecourse', 'australia', 'during']\n",
            "------------------------------\n",
            "Length of vector: 100\n",
            "[-1.4459532   3.6079936   2.031353   -4.2358317  -3.1127784  -1.503725\n",
            "  1.5746497   1.054116   -0.40869266  0.397116   -3.2129698  -1.93603\n",
            " -0.98260087  1.5290232  -1.5685167   0.63508     2.6700141  -2.3093402\n",
            " -0.3023347  -0.07433224  2.5330417   0.82632935  0.2936802  -1.3621647\n",
            "  1.4337307  -2.449087   -3.6120603   1.94268     0.63194895  1.4506592\n",
            " -1.7105377  -3.1833668   2.2844806   1.7383822   1.8047451   1.5046903\n",
            "  1.9914391  -1.4613127   0.17004342  0.3009173  -0.10525012 -2.0092938\n",
            " -2.39924     1.1639574   1.56456     0.7946466   1.236838   -0.04696937\n",
            "  2.1879904  -0.29786253 -0.22740117 -2.6783845   0.7651333  -0.47121862\n",
            "  1.4081092   0.76695794  2.0977302   0.4006395   0.72253627 -0.41583297\n",
            "  4.7662954  -0.05798725 -3.6481273  -0.48207873  1.4958351   1.203132\n",
            " -3.209097    1.7956781   1.600241    1.0826507   2.5443885   1.5092714\n",
            "  0.07711823 -1.3245293  -0.95775384  1.5664374   1.4952917  -0.913193\n",
            " -0.94059426 -1.0927302  -1.3909949  -0.6532051  -3.0067894   0.4469977\n",
            "  2.5290115   2.673812    1.6630682   0.17312296  2.3815246  -1.1948164\n",
            " -3.172195   -1.78363     0.41301212  3.9684222  -2.861974    0.515266\n",
            "  2.7292943  -1.1105433  -2.4111476   2.6917896 ]\n",
            "------------------------------\n",
            "Similarity between film and drama: 0.48726758\n",
            "Similarity between film and tiger: 0.17702298\n",
            "------------------------------\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "4CNy0Goj6Zsx"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}