{
 "cells": [
  {
   "cell_type": "markdown",
   "source": [
    "![](helper/1.PNG)\r\n",
    "\r\n",
    "* Input: Grayscale 572*572 \r\n",
    "* Output: 388*388 2 output classes\r\n",
    "* At every level two 3*3 **valid** convolution \r\n",
    "* * Valid convolution (no padding): 2nd layer shape = (572-3)/1+1 = 570  {(input-filter)/stride+1 }\r\n",
    "* downsample 2*2 stride 2 downsampling\r\n",
    "* Upsample using transpose convolution \r\n",
    "* * The resulting layer is a concatenation of \r\n",
    "* * * skip connection (we need to crop the image in the left of U to match dimension in the output upsampled layer)\r\n",
    "* * * Upsampling\r\n",
    "\r\n",
    "* final 1*1 conv to get to number of classes\r\n",
    "\r\n",
    "\r\n",
    "* The downsample gives what we are looking at. Upsample (with skip connection) tells where it is.\r\n",
    "* For a large image, they take tiles, put padding with mirroring strategy (so that context is there). Then stitch the results together "
   ],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "#### Why not 3*3 same convolutions? \r\n",
    "* The receptive field doesnt grow that fast \r\n",
    "* Computationally expensive"
   ],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [],
   "metadata": {}
  }
 ],
 "metadata": {
  "orig_nbformat": 4,
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}