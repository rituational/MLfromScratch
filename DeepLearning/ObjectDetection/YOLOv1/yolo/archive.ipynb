{
 "metadata": {
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3"
  },
  "orig_nbformat": 4,
  "kernelspec": {
   "name": "python3",
   "display_name": "Python 3.8.3 64-bit ('base': conda)"
  },
  "interpreter": {
   "hash": "5290d49bf49c861d1e1b9142ef1e6b5b192d9fd7271105af6336aae767748867"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2,
 "cells": [
  {
   "source": [
    "# YOLO from Scratch \n",
    "\n",
    "Some nuances: \n",
    "* Last layer will  have one filter corresponding to each bounding box prediction. \n",
    "Eg. Below, We have 7*7 grids. 2 anchor boxes for each of them.20 classes.  \n",
    "\n",
    "So,   \n",
    "\n",
    "no of classes {class score} + /[(objectness score {whether object or background} + 4 coordinates {if objeect, else dont care})* no of classes/]*no. of boxes \n",
    "\n",
    "For each cell. We have a matrix of 7*7 with the above depth.\n",
    "\n",
    "![](helper/1.JPG)\n",
    "\n",
    "* Out of the two boxes, we find the box which matches better and reduce the confidence for the other box. So we can only have one class prediction per grid cell (limitation). Hence, in the above calculation, we only one P(class_i|object) rather than two for two boxes. \n",
    "We need to find which box out of the two to choose. According to the paper, the box with higher IOU is responsible for prediction and only that appears in the loss \n",
    "![](helper/2.JPG)\n",
    "![](helper/3.JPG)\n",
    "\n",
    "\n",
    "Important points to note: \n",
    "* Loss function is sum of squared errors. This gives equal weightage to classification and localization error, which may not be desirable. So we give weightage to localization error ($\\lambda$ = 5). \n",
    "* Also, there usually exist lot amny background boxes which may have zero loss and we get a high representation of cells with objects. So we give less weightage to loss from non object boxes to ensure training stability. (not very clear)\n",
    "* We want localization error in smaller objects to be weighted more than same error in bigger objects. Hence we take square of difference of root of width and height. \n",
    "eg. \n",
    "1. gt = 100, pred = 94. mse = 1024, yolo loss component = 0.09 #(100**(1/2)-94**(1/2))**2\n",
    "2. gt = 8, pred = 2, mse = 36, yolo = 2. #(8**(1/2)-2**(1/2))**2\n",
    "We yolo trick penalizes localization error more in smaller boxes (for same magnitude variation in big and small boxes)."
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "source": [],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "source": [],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "    label_matrix = np.zeros([7, 7, 30])\n",
    "    for l in label:\n",
    "        l = l.split(',')\n",
    "        l = np.array(l, dtype=np.int)\n",
    "        xmin = l[0]\n",
    "        ymin = l[1]\n",
    "        xmax = l[2]\n",
    "        ymax = l[3]\n",
    "        cls = l[4]\n",
    "\n",
    "        ## Convert coordinates to [0,1]\n",
    "        x = (xmin + xmax) / 2 / image_w\n",
    "        y = (ymin + ymax) / 2 / image_h\n",
    "        w = (xmax - xmin) / image_w\n",
    "        h = (ymax - ymin) / image_h\n",
    "\n",
    "        # Since output layer has 7*7 grid, this gives us index of the grid responsible for detection. \n",
    "        loc = [7 * x, 7 * y]\n",
    "        loc_i = int(loc[1])\n",
    "        loc_j = int(loc[0])\n",
    "\n",
    "        ## x, y are offset inside that grid cell.\n",
    "        y = loc[1] - loc_i\n",
    "        x = loc[0] - loc_j\n",
    "\n",
    "        #We need to store GT for only the grid responsible (mid point of GT lies in that grid)\n",
    "        # Does the below code store the labels in box1, keeping box2 empty? Doubt\n",
    "\n",
    "        if label_matrix[loc_i, loc_j, 24] == 0:\n",
    "            label_matrix[loc_i, loc_j, cls] = 1 # index 0 to 20 are conditional class probabilities \n",
    "            label_matrix[loc_i, loc_j, 20:24] = [x, y, w, h]\n",
    "            label_matrix[loc_i, loc_j, 24] = 1  # response"
   ]
  },
  {
   "source": [
    "*Reference*\n",
    "\n",
    "(slide 28) from https://docs.google.com/presentation/d/1kAa7NOamBt4calBU9iHgT8a86RRHz9Yz2oh4-GTdX6M/edit#slide=id.p"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "source": [
    "output and label relative to the cell, x,y,w,h. x,y belongs to [0,1], w,h can be greater thn 1 if object is larger than that cell. \n",
    "![](helper/5.JPG)\n",
    "![](helper/6.JPG)\n",
    "\n",
    "Target shape for one image = S*S*25  \n",
    "Prediction shape for one image = S*S*30 (Target/GT has one label bb, while for prediction we are predicting two boxes per cell )"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "source": [
    "Doubts: \n",
    "how pc ensured to be between 0,1 in prediction?\n",
    "How exactly backpropagation happens from 7*7*30 layer to fully connected layer?\n",
    "What if multiple objects have box in on cell? Any way to detect that and finegrain the grid? Or we will just train for the last object updated?\n"
   ],
   "cell_type": "markdown",
   "metadata": {}
  }
 ]
}