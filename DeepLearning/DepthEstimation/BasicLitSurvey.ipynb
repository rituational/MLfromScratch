{
 "cells": [
  {
   "cell_type": "markdown",
   "source": [
    "## Stereo "
   ],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "# Depth Estimation\r\n",
    "\r\n",
    "### Hardware \r\n",
    "* Dual camera\r\n",
    "* Dual pixel: Two photo diode in the same lens acts as stereo pair\r\n",
    "* sensors: IR, LASAR, LIDAR \r\n",
    "\r\n",
    "### Software \r\n",
    "\r\n",
    "#### Multiple image method\r\n",
    "* Keypoint matching between two images captured to get depth. \r\n",
    "* To make process robust, use accelerometer/other sensor measurement to know how much movement occured (visual inertial odometry)\r\n",
    "* "
   ],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "### Depth from Disparity \r\n",
    "* Assuming the lens are placed parallely, to find the actual depth Z, we get the following formula. \r\n",
    "* Disparity is the distance between point of intersection for the two lens. \r\n",
    "* More the depth, less this distance: disparity. \r\n",
    "* For moon, since depth is infinite, disparity is close to zero and we feel moon is moving with us. We have lost the sense of depth \r\n",
    "\r\n",
    "![](helper/1.JPG)\r\n",
    "![](helper/2.JPG)"
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "Ref: https://github.com/scott89/awesome-depth (list of different depth estimation techniques)"
   ],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [],
   "metadata": {}
  }
 ],
 "metadata": {
  "orig_nbformat": 4,
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}