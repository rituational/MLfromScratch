{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.layers import Conv2D, MaxPooling2D, Input\n",
    "from tensorflow.keras.models import Model\n",
    "from tensorflow.keras.utils import plot_model\n",
    "from tensorflow.keras.layers import concatenate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# basic inception block \n",
    "\n",
    "def naive_inception_block(in_layer, f1, f3, f5):\n",
    "    conv_1 = Conv2D(f1, (1,1), padding = 'same')(in_layer)\n",
    "    conv_3 = Conv2D(f3, (3,3), padding = 'same')(in_layer)\n",
    "    conv_5 = Conv2D(f5, (5,5), padding = 'same')(in_layer)\n",
    "    pool = MaxPooling2D((3,3), strides=(1,1), padding='same')(in_layer)\n",
    "    \n",
    "    out_layer = concatenate((conv_1, conv_3, conv_5, pool), axis = 1)\n",
    "    \n",
    "## 1*1 convolution were added to reduce the filters before 3*3 and 5*5 convolution to improve computational performance.\n",
    "\n",
    "def inception_block(in_layer, f1, f2_in, f2_out, f3_in, f3_out, f4_out):\n",
    "    conv_1 = Conv2D(f1, (1,1), padding = 'same')(in_layer)\n",
    "    \n",
    "    conv_2 = Conv2D(f2_in, (1,1), padding = 'same')(in_layer)\n",
    "    conv_2 = Conv2D(f2_out, (3,3), padding = 'same')(conv_2)\n",
    "    \n",
    "    conv_3 = Conv2D(f3_in, (1,1), padding = 'same')(in_layer)\n",
    "    conv_3 = Conv2D(f3_out, (3,3), padding = 'same')(conv_3)\n",
    "    \n",
    "    pool = MaxPooling2D((3,3), strides=(1,1), padding='same')(in_layer)\n",
    "    pool = Conv2D(f4_out, (1,1), padding = 'same')(pool)\n",
    "    \n",
    "    out_layer = concatenate([conv_1, conv_2, conv_3, pool], axis = -1)\n",
    "    \n",
    "    return out_layer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"model_2\"\n",
      "__________________________________________________________________________________________________\n",
      "Layer (type)                    Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      "input_6 (InputLayer)            [(None, 256, 256, 3) 0                                            \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_31 (Conv2D)              (None, 256, 256, 96) 384         input_6[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_33 (Conv2D)              (None, 256, 256, 16) 64          input_6[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "max_pooling2d_5 (MaxPooling2D)  (None, 256, 256, 3)  0           input_6[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_30 (Conv2D)              (None, 256, 256, 64) 256         input_6[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_32 (Conv2D)              (None, 256, 256, 128 110720      conv2d_31[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_34 (Conv2D)              (None, 256, 256, 32) 4640        conv2d_33[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_35 (Conv2D)              (None, 256, 256, 32) 128         max_pooling2d_5[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_5 (Concatenate)     (None, 256, 256, 256 0           conv2d_30[0][0]                  \n",
      "                                                                 conv2d_32[0][0]                  \n",
      "                                                                 conv2d_34[0][0]                  \n",
      "                                                                 conv2d_35[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_37 (Conv2D)              (None, 256, 256, 128 32896       concatenate_5[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_39 (Conv2D)              (None, 256, 256, 32) 8224        concatenate_5[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "max_pooling2d_6 (MaxPooling2D)  (None, 256, 256, 256 0           concatenate_5[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_36 (Conv2D)              (None, 256, 256, 128 32896       concatenate_5[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_38 (Conv2D)              (None, 256, 256, 192 221376      conv2d_37[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_40 (Conv2D)              (None, 256, 256, 96) 27744       conv2d_39[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_41 (Conv2D)              (None, 256, 256, 64) 16448       max_pooling2d_6[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_6 (Concatenate)     (None, 256, 256, 480 0           conv2d_36[0][0]                  \n",
      "                                                                 conv2d_38[0][0]                  \n",
      "                                                                 conv2d_40[0][0]                  \n",
      "                                                                 conv2d_41[0][0]                  \n",
      "==================================================================================================\n",
      "Total params: 455,776\n",
      "Trainable params: 455,776\n",
      "Non-trainable params: 0\n",
      "__________________________________________________________________________________________________\n",
      "Failed to import pydot. You must install pydot and graphviz for `pydotprint` to work.\n"
     ]
    }
   ],
   "source": [
    "visible = Input(shape=(256, 256, 3))\n",
    "# add inception block 1\n",
    "layer = inception_block(visible, 64, 96, 128, 16, 32, 32)\n",
    "# add inception block 1\n",
    "layer = inception_block(layer, 128, 128, 192, 32, 96, 64)\n",
    "# create model\n",
    "model = Model(inputs=visible, outputs=layer)\n",
    "# summarize model\n",
    "model.summary()\n",
    "# plot model architecture\n",
    "plot_model(model, show_shapes=True, to_file='inception_module.png')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![](/helper/inception.JPG)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![](helper/inception.jpg)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* By concatenation, we are stacking the filters of all the parallel branches together (axis = -1). in concatenate_2 output is 480 (128+192+96+64) \n",
    "* the small kernels have more no of filteres while 5*5 has lesser (may be for compute? )\n",
    "* Feeding 480 filters to the next layer will be very compute intensive hence the 1*1 convolution. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
